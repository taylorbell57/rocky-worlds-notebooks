{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a30ba3-59ef-4c15-9f94-c651b3098d9a",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_header.png' alt=\"stsci_logo\" width=\"900px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0e898-ed9f-4969-873a-55a6a99774b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a4c33-d7f2-4551-bce4-1d841265b6d3",
   "metadata": {},
   "source": [
    "# RW-DDT Quicklook Analysis Template Notebook\n",
    "\n",
    "**Authors**: Taylor James Bell (ESA/AURA for STScI)<br>\n",
    "**Last Updated**: August 04, 2025<br>\n",
    "**jwst Pipeline Version**: 1.18.0 (Build 11.3)<br>\n",
    "**Eureka! Pipeline Version**: https://github.com/kevin218/Eureka/tree/tjb_rwddt\n",
    "\n",
    "Note that additional contextual information can be found in `README_Quicklook.md`\n",
    "\n",
    "**Purpose**:<br/>\n",
    "\n",
    "It should not be necessary to edit any cells other than in the [1. Define your eventlabel and top directory](#1.-Define-your-eventlabel-and-top-directory) section and the [5.2 Setting up the Stage 5 EPF](#5.2-Setting-up-the-Stage-5-EPF) subsection unless you want to manually explore/optimize different data processing steps.\n",
    "\n",
    "**Data**:<br/>\n",
    "This notebook assumes the Stage 1 rateints files have already been downloaded from MAST using the `rocky-worlds-utils/download_JWST.py` script.\n",
    "\n",
    "**JWST pipeline version and CRDS context**:<br/>\n",
    "This notebook was written for the calibration pipeline version given above and uses the context associated with this version of the JWST Calibration Pipeline. Information about this and other contexts can be found in the JWST Calibration Reference Data System (CRDS) [server]((https://jwst-crds.stsci.edu/)). If you use different pipeline\n",
    "versions, please refer to the table [here](https://jwst-crds.stsci.edu/display_build_contexts/) to determine what context to use. To learn more about the differences for the pipeline, read the relevant [documentation](https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline/jwst-operations-pipeline-build-information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac46f2b-6c04-4960-bb56-aea9e929d24e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [0. Importing the required components](#0.-Importing-the-required-components)\n",
    "- [1. Define your eventlabel and top directory](#1.-Define-your-eventlabel-and-top-directory)\n",
    "- [2. Stage 2](#2.-Stage-2)\n",
    "- [3. Stage 3 - Pixels to Lightcurve](#3.-Stage-3---Pixels-to-Lightcurve)\n",
    "- [4. Stage 4 - Removing time-series outliers](#4.-Stage-4---Removing-time-series-outliers)\n",
    "- [5. Stage 5 - Fitting the lightcurve](#5.-Stage-5---Fitting-the-lightcurve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61429e-156d-45da-b07a-019428463f84",
   "metadata": {},
   "source": [
    "## 0. Importing the required components\n",
    "\n",
    "There should be no need to change any of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47179898-941f-409b-b70a-10f483cff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a bunch of Eureka! components\n",
    "import eureka.lib.plots\n",
    "import eureka.S2_calibrations.s2_calibrate as s2\n",
    "import eureka.S3_data_reduction.s3_reduce as s3\n",
    "import eureka.S4_generate_lightcurves.s4_genLC as s4\n",
    "import eureka.S5_lightcurve_fitting.s5_fit as s5\n",
    "\n",
    "# Set up some parameters to make plots look nicer. You can set usetex=True if you have LaTeX installed\n",
    "eureka.lib.plots.set_rc(style='eureka', usetex=False, filetype='.png')\n",
    "\n",
    "# Some imports to interact with outputs within the Jupyter notebook\n",
    "from IPython.display import Image, display\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf95ae-2975-40b0-8fd3-039097f32e2f",
   "metadata": {},
   "source": [
    "## 1. Define your eventlabel and top directory\n",
    "\n",
    "Next, we need to choose a short, meaningful label (without spaces) that describes the data we're currently working on. This eventlabel will determine will give nicknames to all your output folders and files.\n",
    "\n",
    "We also need to tell the notebook where all our data is going to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd379f0e-1ab2-4ec1-9d5f-80d1f2a6312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter in a custom eventlabel that will be used to distinguish the outputs\n",
    "# from all subsequent processing\n",
    "eventlabel = '' ## <- ENTER YOUR LABEL HERE\n",
    "\n",
    "# Specify here the top directory that will contain all ingested and output files\n",
    "topdir = '/home/rwddt' ## <- ENTER YOUR TOPDIR HERE (leave at /home/rwddt if using Docker)\n",
    "\n",
    "# Specify your analysis name here (analysis if using Docker, Analysis_A otherwise)\n",
    "analysis_name = 'analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8f79a-f776-4f38-8400-b933a853e5d4",
   "metadata": {},
   "source": [
    "## 2. Stage 2\n",
    "\n",
    "### 2.1 Setting up the Stage 2 ECF\n",
    "\n",
    "For quick-look analyses, there is no need to change any of the Stage 2 settings beyond what is provided in the template, so we'll just read those defaults in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad2700-1fdc-4ab2-8606-0032f61f469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_ecf_contents = f\"\"\"# Eureka! Control File for Stage 2: Data Reduction\n",
    "\n",
    "# Stage 2 Documentation: https://eurekadocs.readthedocs.io/en/latest/ecf.html#stage-2\n",
    "\n",
    "pmap\t\t\t\t1364\n",
    "\n",
    "# Project directory\n",
    "topdir              {topdir}\n",
    "\n",
    "# Directories relative to topdir\n",
    "inputdir            MAST_Stage1\n",
    "outputdir           {analysis_name}/Quicklook/Stage2\n",
    "\"\"\"\n",
    "\n",
    "# This will save the ECF as a file that the next cell can read-in\n",
    "with open(f'./S2_{eventlabel}.ecf', 'w') as f:\n",
    "    f.write(s2_ecf_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a6869-d514-4549-ac84-5ddbe26dde40",
   "metadata": {},
   "source": [
    "### 2.2 Running Stage 2\n",
    "\n",
    "Here we run the Eureka! Stage 2 pipeline using the settings we defined above. This should take <1 minute, but that will depend on the data volume of the observation you're working on and the specifics of your CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348819af-e2ba-491a-becb-9c2926fd06a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s2_meta = s2.calibrateJWST(eventlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a00ed-252c-4edf-b4ba-e1929b81c0e4",
   "metadata": {},
   "source": [
    "## 3. Stage 3 - Pixels to Lightcurve\n",
    "\n",
    "### 3.1 Setting up the Stage 3 ECF\n",
    "\n",
    "For quick-look analyses, there is no need to change any of the Stage 3 settings beyond what is provided in the template, so we'll just read those defaults in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba0822-73db-4752-8321-6439fd8d20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_ecf_contents = f\"\"\"# Eureka! Control File for Stage 3: Data Reduction\n",
    "\n",
    "# Stage 3 Documentation: https://eurekadocs.readthedocs.io/en/latest/ecf.html#stage-3\n",
    "\n",
    "ncpu            16\n",
    "max_memory      1.5\n",
    "\n",
    "pmap            1364\n",
    "\n",
    "# Background parameters\n",
    "ff_outlier      True        # Set False to use only background region (recommended for deep transits)\n",
    "                            # Set True to use full frame (works well for shallow transits/eclipses)\n",
    "bg_thresh       [5,5]\n",
    "interp_method   linear      # Interpolate bad pixels. Options: None (if no interpolation should be performed), linear, nearest, cubic\n",
    "\n",
    "# Centroiding parameters\n",
    "centroid_method mgmc        # Method used for centroiding. Options: mgmc, fgc\n",
    "ctr_guess\t\tfits    \t# Initial guess of centroid position. If None, will first perform centroiding on whole frame (can sometimes fail)\n",
    "\n",
    "# Photometric extraction parameters\n",
    "phot_method     photutils   # photutils (aperture photometry using photutils), poet (aperture photometry using code from POET), or optimal (for optimal photometric extraction)\n",
    "aperture_edge   exact       # center (pixel is included only if its center lies within the aperture), or exact (pixel is weighted by the fractional area that lies within the aperture)\n",
    "photap          5           # Size of photometry aperture radius in pixels\n",
    "skyin           16          # Inner sky annulus edge, in pixels\n",
    "skywidth        30          # Width of the sky annulus, in pixels\n",
    "\n",
    "# Diagnostics\n",
    "nplots          3\n",
    "\n",
    "# Project directory\n",
    "topdir          {topdir}\n",
    "\n",
    "# Directories relative to topdir\n",
    "inputdir        {analysis_name}/Quicklook/Stage2\n",
    "outputdir       {analysis_name}/Quicklook/Stage3\n",
    "\"\"\"\n",
    "\n",
    "# This will save the ECF as a file that the next cell can read-in\n",
    "with open(f'./S3_{eventlabel}.ecf', 'w') as f:\n",
    "    f.write(s3_ecf_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718393c-87fe-44fa-ab82-c80cd3d2da6f",
   "metadata": {},
   "source": [
    "### 3.2 Running Stage 3\n",
    "\n",
    "Here we run the Eureka! Stage 3 pipeline using the settings we defined above. This should take ~1 minute, but that will depend on the data volume of the observation you're working on and the specifics of your CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc45e30-c515-424c-a9c4-c1d2575379fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, s3_meta = s3.reduce(eventlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cc5d49-f7b4-403c-8cd5-a78bbd811daf",
   "metadata": {},
   "source": [
    "### 3.3 Investigating the Stage 3 outputs\n",
    "\n",
    "#### Figures 3306\n",
    "\n",
    "These figures show the results of the centroiding algorithm. You should examine these and ensure that there is a red \"x\" approximately centered on the stellar PSF, a red circle encircling most of the core of the stellar PSF, and a white annulus that will be used for background-subtraction that does not contain other nearby stars or galaxies. If you do not see a stellar PSF under the red \"x\" or see other sources in the background annulus, reach out to your TSO Mentor and/or Taylor Bell to investigate this issue further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dcba8-e990-4d2e-8371-471e9a5f4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = np.sort(glob(s3_meta.outputdir+'figs/fig3306*'))\n",
    "for figure in figures:\n",
    "    display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97879b9-d869-49d4-a776-153dd2585d77",
   "metadata": {},
   "source": [
    "#### Figure 3109\n",
    "\n",
    "This is a summary plot of the centroiding results on all of the integrations, showing changes in the centroid position and PSF-width as a function of time. You can expect some noise/jitter in each of these parameters, and possibly a small number of 1-integration spikes that may be caused by unmasked cosmic rays. You can also expect a small, gradual drift in the PSF width (especially at the start of the observation). If, however, you see any sudden and large shifts in the centroid position or PSF width (that may be caused by failed tracking or a mirror tilt event), reach out to Taylor Bell to assess whether this is indicative of a failed observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013700ed-a10c-42f2-8347-fa37a872e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = glob(s3_meta.outputdir+'figs/fig3109*')[0]\n",
    "display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca773e44-a5dd-41f6-a4c6-b6cd7f748e26",
   "metadata": {},
   "source": [
    "#### Figure 3108\n",
    "\n",
    "This is a first look at the lightcurve of our target. You may see a small number of large outliers which may be caused by unmasked cosmic rays or bad pixels; these will be taken care of in Stage 4 and are not immediately of concern. There will likely also be a gradual downward trend in the data, which may be especially steep in the first tens of integrations, as the detector and instrument settle and any persistence decays. If a substantial number of the integrations look to be extreme outliers, contact Taylor Bell to assess whether this is indicative of a major issue (think >10 points that are >100 sigma away or something, and don't worry about >5 sigma outliers at this point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78e0bd-9c49-409e-984f-0c60e6be3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = glob(s3_meta.outputdir+'figs/fig3108*')[0]\n",
    "display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766b4ea-a792-41ee-b22b-36b301a120dd",
   "metadata": {},
   "source": [
    "## 4. Stage 4 - Removing time-series outliers\n",
    "\n",
    "### 4.1 Setting up the Stage 4 ECF\n",
    "\n",
    "For quick-look analyses, there is no need to change any of the Stage 4 settings beyond what is provided in the template, so we'll just read those defaults in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec49be-a784-4b70-b6eb-1eb8808face6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4_ecf_contents = f\"\"\"# Eureka! Control File for Stage 4: Generate Lightcurves\n",
    "\n",
    "# Stage 4 Documentation: https://eurekadocs.readthedocs.io/en/latest/ecf.html#stage-4\n",
    "\n",
    "# Number of spectroscopic channels spread evenly over given wavelength range\n",
    "nspecchan       1\n",
    "compute_white   False\n",
    "\n",
    "# Parameters for sigma clipping\n",
    "clip_binned     True    # Whether or not sigma clipping should be performed on the binned 1D time series\n",
    "sigma           3.5     # The number of sigmas a point must be from the rolling median to be considered an outlier\n",
    "box_width       20      # The width of the box-car filter (used to calculated the rolling median) in units of number of data points\n",
    "maxiters        20      # The number of iterations of sigma clipping that should be performed.\n",
    "boundary        fill    # Use 'fill' to extend the boundary values by the median of all data points (recommended), 'wrap' to use a periodic boundary, or 'extend' to use the first/last data points\n",
    "fill_value      mask    # Either the string 'mask' to mask the outlier values (recommended), 'boxcar' to replace data with the mean from the box-car filter, or a constant float-type fill value.\n",
    "\n",
    "# Project directory\n",
    "topdir          {topdir}\n",
    "\n",
    "# Directories relative to topdir\n",
    "inputdir        {analysis_name}/Quicklook/Stage3\n",
    "outputdir       {analysis_name}/Quicklook/Stage4\n",
    "\"\"\"\n",
    "\n",
    "# This will save the ECF as a file that the next cell can read-in\n",
    "with open(f'./S4_{eventlabel}.ecf', 'w') as f:\n",
    "    f.write(s4_ecf_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1646d-ed7a-4a0d-8e8f-0c5df9896669",
   "metadata": {},
   "source": [
    "### 4.2 Running Stage 4\n",
    "\n",
    "Here we run the Eureka! Stage 4 pipeline using the settings we defined above. This should take << 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79cd41-619c-4422-9533-db2b9dfe7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, lc, s4_meta = s4.genlc(eventlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714600d-d0c9-4297-b370-89dd3af956f6",
   "metadata": {},
   "source": [
    "### 4.3 Investigating the Stage 4 outputs\n",
    "\n",
    "#### Figure 4102\n",
    "\n",
    "This shows the sigma-clipped version of the lightcurve of our target, which should look very similar to Figure 3108 but without extreme outliers. These are the data points which will be fitted in Stage 5. If there are still substantial outliers, you will need to adjust the `sigma` and `box_width` settings in your Stage 4 ECF in order to properly catch all the outliers. This might take a bit of guess-and-check work, but if you can't find reasonable settings reach out to your TSO Mentor and/or Taylor Bell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9077b32-aac0-4c8b-a1c1-158c46ec81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = glob(s4_meta.outputdir+'figs/fig4102*')[0]\n",
    "display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb306d27-e21e-4f62-ba98-b4f69d0e6b64",
   "metadata": {},
   "source": [
    "## 5. Stage 5 - Fitting the lightcurve\n",
    "\n",
    "### 5.1 Setting up the Stage 5 ECF\n",
    "\n",
    "For quick-look analyses, there is no need to change any of the Stage 5 ECF settings beyond what is provided in the template, so we'll just read those defaults in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6f8a2-9936-4cde-9486-8718d8280fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_ecf_contents = f\"\"\"# Eureka! Control File for Stage 5: Lightcurve Fitting\n",
    "\n",
    "# Stage 5 Documentation: https://eurekadocs.readthedocs.io/en/latest/ecf.html#stage-5\n",
    "\n",
    "ncpu            16    # The number of CPU threads to use when running emcee or dynesty in parallel\n",
    "\n",
    "fit_par         ./S5_{eventlabel}.epf\n",
    "fit_method      [dynesty]\n",
    "run_myfuncs     [batman_ecl, polynomial, expramp, xpos, ypos, xwidth, ywidth]\n",
    "\n",
    "#GP inputs\n",
    "kernel_inputs   ['time']  # options: time\n",
    "kernel_class    ['Matern32']  # options: ExpSquared, Matern32, Exp, RationalQuadratic for george, Matern32 for celerite (sums of kernels possible for george separated by commas)\n",
    "GP_package      'celerite'  # options: george, celerite\n",
    "\n",
    "# Manual clipping in time\n",
    "manual_clip     [[None,50]]   # Remove the first 50 integrations which will be most affected by detector settling\n",
    "\n",
    "# dynesty fitting parameters\n",
    "run_nlive       'min'         # Must be > ndim * (ndim + 1) // 2. Use 'min' to use the minimum safe number\n",
    "run_bound       'multi'\n",
    "run_sample      'rwalk'\n",
    "run_tol         0.01\n",
    "\n",
    "# Plotting controls\n",
    "interp          True    # Should astrophysical model be interpolated (useful for uneven sampling like that from HST)\n",
    "\n",
    "# Diagnostics\n",
    "isplots_S5      5       # Generate few (1), some (3), or many (5) figures (Options: 1 - 5)\n",
    "\n",
    "# Project directory\n",
    "topdir          {topdir}\n",
    "\n",
    "# Directories relative to topdir\n",
    "inputdir        {analysis_name}/Quicklook/Stage4\n",
    "outputdir       {analysis_name}/Quicklook/Stage5\n",
    "\"\"\"\n",
    "\n",
    "# This will save the ECF as a file that the next cell can read-in\n",
    "with open(f'./S5_{eventlabel}.ecf', 'w') as f:\n",
    "    f.write(s5_ecf_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd644e5-cc80-422e-ab9e-6b4e71f35b49",
   "metadata": {},
   "source": [
    "### 5.2 Setting up the Stage 5 EPF\n",
    "\n",
    "Update the astrophysical parameter priors based on those provided in the relevant Jira ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05702e0b-7544-42a5-9cfb-31faee00051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_epf_contents = \"\"\"\n",
    "# Stage 5 Fit Parameters Documentation: https://eurekadocs.readthedocs.io/en/latest/ecf.html#stage-5-fit-parameters\n",
    "\n",
    "#Name         Value                 Free?            PriorPar1        PriorPar2    PriorType\n",
    "# \"Free?\" can be free, fixed, white_free, white_fixed, shared, or independent\n",
    "# PriorType can be U (Uniform), LU (Log Uniform), or N (Normal).\n",
    "# If U/LU, PriorPar1 and PriorPar2 represent lower and upper limits of the parameter/log(the parameter).\n",
    "# If N, PriorPar1 is the mean and PriorPar2 is the standard deviation of a Gaussian prior.\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "rp          YourRadiusHere      'fixed'\n",
    "fp          YourFpHere          'free'           YourFpHere    2000e-6     N\n",
    "# ------------------\n",
    "# Orbital parameters\n",
    "# ------------------\n",
    "per         YourPerHere         'fixed'\n",
    "t_secondary YourTsecHere        'fixed'\n",
    "inc         YourIncHere         'fixed'\n",
    "a           YourAHere           'fixed'\n",
    "ecc         0.                  'fixed'\n",
    "w           90.                 'fixed'\n",
    "time_offset 0                   'independent'\n",
    "# The following two lines are commented out, but you can uncomment them (while commenting out the ecc and w lines above) and edit them if needed for your planet\n",
    "# ecosw       YourEcoswHere       'fixed'          YourEcoswHere YourEcoswUncertHere N\n",
    "# esinw       YourEsinwHere       'fixed'          YourEsinwHere YourEsinwUncertHere N\n",
    "# --------------------------------------------------------------------------\n",
    "# Systematic variables (these can be left as-is for the Quick-Look analysis)\n",
    "# --------------------------------------------------------------------------\n",
    "# Polynomial Parameters\n",
    "c0          0.999               'free'           0.999         0.01        N\n",
    "c1          -0.002              'free'           0.0           0.1         N\n",
    "# Ramp Parameters\n",
    "r0          0.002               'free'           0.0           0.01        N\n",
    "r1          50                  'free'           3             300         U\n",
    "# Centroid decorrelation parameters\n",
    "ypos        0.0                 'free'           0.0           0.5         N\n",
    "xpos        0.0                 'free'           0.0           0.5         N\n",
    "ywidth      0.0                 'free'           0.0           0.5         N\n",
    "xwidth      0.0                 'free'           0.0           0.5         N\n",
    "# White noise\n",
    "scatter_mult 1.4                'free'           0.8           10          U\n",
    "\"\"\"\n",
    "\n",
    "# This will save the EPF as a file that the next cell can read-in\n",
    "with open(f'./S5_{eventlabel}.epf', 'w') as f:\n",
    "    f.write(s5_epf_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc541bf-13f8-44c6-bec8-c173d6c4c206",
   "metadata": {},
   "source": [
    "### 5.3 Running Stage 5\n",
    "\n",
    "Here we run the Eureka! Stage 5 pipeline using the settings we defined above. This should take ~1 minute or less, but that will depend on the data volume of the observation you're working on, the specifics of your CPU, and how well the model matches your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb9387-aba0-4fad-afa6-3d8cbb5d250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_meta = s5.fitlc(eventlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f75fae-2f8d-4a73-886b-e7b564c2ff26",
   "metadata": {},
   "source": [
    "### 5.4 Investigating the Stage 5 outputs\n",
    "\n",
    "#### Figure 5101 _dynestyStartingPoint\n",
    "\n",
    "This is a plot showing the starting point of the fit to the observations. The top panel shows the raw data points in blue (the same data from Figure 4102), and the starting point of the model fit in grey. You should make sure that there is an eclipse signal shown in the grey model (don't worry whether that same eclipse depth is obvious in the blue points yet); if there is no eclipse signal shown in the grey model, then it is likely that you have incorrectly entered one of the astrophysical parameters, with the most likely culprit being that you've incorrectly specified t_secondary (note that this parameter should be in BMJD_TDB which is equal to BJD_TDB - 2,400,000.5). At this point, do not worry if the model doesn't do a very good job at fitting the data; this is just where the model was initialized, and the fitting process is pretty robust to bad initial guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6fc03-9a38-4aab-b06b-c27895c4feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = glob(s5_meta.outputdir+'figs/fig5101*_dynestyStartingPoint*')[0]\n",
    "display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990c7b4-8edc-41ff-aaad-28ed6a110142",
   "metadata": {},
   "source": [
    "#### Figure 5101\n",
    "\n",
    "This is the same style of plot as the _dynestyStartingPoint version, but instead shows the final fit to the data. The grey model points in the top panel will likely no longer look like a smooth line but instead exhibit a noticeable amount of jitter which is the result of the centroid-detrending model fit which is able to slightly reduce the final noise level in the lightcurve. In the middle panel, the systematic noise model has been removed from both the data (in blue) and the model (in grey), and the grey model will now show only the fitted eclipse signal which should do a reasonable job at fitting the observations. The residuals of the fit are shown in the bottom panel, which should be centered around 0 and should ideally not show any residual trends (only showing Gaussian scatter). If the model appears to be quite poorly fit to the data, reach out to Taylor Bell who will help investigate the cause of this poor fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fadd5f-75b1-4a48-b1fb-f3110bc1d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = glob(s5_meta.outputdir+'figs/fig5101*dynesty.png')[0]\n",
    "display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef28a84-d4a2-47e9-8c2b-af57f0d66b21",
   "metadata": {},
   "source": [
    "#### Figure 5302\n",
    "\n",
    "This figure shows a histogram of the residuals of the fit to the model in blue, along with a black curve showing the expected Gaussian distribution of the residuals given the fitted noise level. The blue empirical histogram and the black expected distribution should be reasonably well matched, and any points lying beyond -5 or +5 are indicative of outliers that were missed during the Stage 4 sigma-clipping. Related to this figure, you should also check the fitted value for scatter_mult that was printed to your terminal at the end of the quicklook analysis (which is also printed in the Stage5/S5_.../ap5_bg16_46/S5_....log file if you've lost access to the terminal outputs). This parameter is what scales the estimated uncertainties on each integration, with a value of 1.0 meaning that Stage 3 perfectly estimated the noise level. It is entirely expected that this value will be larger than 1.0 (likely something between 1-2) since Stage 3 doesn't account for background noise levels (instead only accounting for Poisson noise from our host star). If, however, the fitted scatter_mult value is very large (>3 or something), this is likely indicative of especially noisy data and may indicate a failed observation; contact Taylor Bell for help in investigating the source of this excess noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e883968-274e-4be6-9676-f93ed6311b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = glob(s5_meta.outputdir+'figs/fig5302*')[0]\n",
    "display(Image(filename=figure, embed=True, width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e569fa-851f-40cb-8efc-3df22318a086",
   "metadata": {},
   "source": [
    "## The End!\n",
    "\n",
    "By now you should have all the details you need to determine whether or not the observations were successful, and if they were not successful have at least some preliminary ideas of why the observations might have failed. Make sure to mark your progress on the relevant Jira ticket and write-up your findings for a quick report to share with the rest of the CIT.\n",
    "\n",
    "P.S., many other figures are produced in Stages 3--5, but detailed investigations of those figures are beyond the scope of our quicklook analysis and will be examined in more detail during the deep-dive analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eureka_rwddt]",
   "language": "python",
   "name": "conda-env-eureka_rwddt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
